{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cbdcbd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from aif360.datasets import StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from common_utils import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08426f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school  sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
       "0     GP    0   18       U     GT3       A     4     4  at_home   teacher   \n",
       "1     GP    0   17       U     GT3       T     1     1  at_home     other   \n",
       "2     GP    0   15       U     LE3       T     1     1  at_home     other   \n",
       "3     GP    0   15       U     GT3       T     4     2   health  services   \n",
       "4     GP    0   16       U     GT3       T     3     3    other     other   \n",
       "\n",
       "   ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0  ...      4        3      4     1     1      3        4   0  11  11  \n",
       "1  ...      5        3      3     1     1      3        2   9  11  11  \n",
       "2  ...      4        3      2     2     3      3        6  12  13  12  \n",
       "3  ...      3        2      2     1     1      5        0  14  14  14  \n",
       "4  ...      4        3      2     1     2      5        0  11  13  13  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"student-por.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c9206d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex  Dalc\n",
      "0    1       305\n",
      "     2        58\n",
      "     3        11\n",
      "     4         7\n",
      "     5         2\n",
      "1    1       146\n",
      "     2        63\n",
      "     3        32\n",
      "     4        10\n",
      "     5        15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Gathering Graph Data for Sex\n",
    "sexCounts = df.groupby(['sex', 'Dalc']).size()\n",
    "print (sexCounts)\n",
    "sexCounts.to_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1dd6541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age  absences\n",
      "15   0           47\n",
      "     1            2\n",
      "     2           21\n",
      "     3            1\n",
      "     4           16\n",
      "                 ..\n",
      "20   8            3\n",
      "     12           1\n",
      "21   0            1\n",
      "     21           1\n",
      "22   12           1\n",
      "Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 2 - Gathering Graph Data for Age\n",
    "ageCounts = df.groupby(['age', 'absences']).size()\n",
    "print (ageCounts)\n",
    "ageCounts.to_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d483b192",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               instance weights            features                     labels\n",
      "                                protected attribute                           \n",
      "                                                sex   age Walc absences       \n",
      "instance names                                                                \n",
      "0                           1.0                 0.0  18.0  1.0      4.0    1.0\n",
      "1                           1.0                 0.0  17.0  1.0      2.0    1.0\n",
      "2                           1.0                 0.0  15.0  3.0      6.0    1.0\n",
      "3                           1.0                 0.0  15.0  1.0      0.0    1.0\n",
      "4                           1.0                 0.0  16.0  2.0      0.0    1.0\n",
      "...                         ...                 ...   ...  ...      ...    ...\n",
      "644                         1.0                 0.0  19.0  2.0      4.0    1.0\n",
      "645                         1.0                 0.0  18.0  1.0      4.0    1.0\n",
      "646                         1.0                 0.0  18.0  1.0      6.0    1.0\n",
      "647                         1.0                 1.0  17.0  4.0      6.0    1.0\n",
      "648                         1.0                 1.0  18.0  4.0      4.0    1.0\n",
      "\n",
      "[649 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Sex|Dalc Fairness Metric Calculation\n",
    "dataset_sex_dalc = StandardDataset(df, \n",
    "                               label_name='Dalc', \n",
    "                               favorable_classes=[1,2,3],\n",
    "                               protected_attribute_names=['sex'], \n",
    "                               privileged_classes=[[0]],\n",
    "                               features_to_keep=['age','Walc','absences']\n",
    "                              )\n",
    "privileged_groups_sex = [{'sex': 0}]\n",
    "unprivileged_groups_sex = [{'sex': 1}]\n",
    "print(dataset_sex_dalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "335927fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Imapct of unprivileged and privileged groups = 0.927818\n",
      "SPD of unprivileged and privileged groups = -0.070486\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_sex_dalc, \n",
    "                                             unprivileged_groups=unprivileged_groups_sex,\n",
    "                                             privileged_groups=privileged_groups_sex)\n",
    "display(Markdown(\"#### Original dataset\"))\n",
    "print(\"Disparate Imapct of unprivileged and privileged groups = %f\" % metric_orig_train.disparate_impact())\n",
    "print(\"SPD of unprivileged and privileged groups = %f\" % metric_orig_train.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13a9e45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               instance weights            features                     labels\n",
      "                                protected attribute                           \n",
      "                                                sex   age Dalc absences       \n",
      "instance names                                                                \n",
      "0                           1.0                 0.0  18.0  1.0      4.0    1.0\n",
      "1                           1.0                 0.0  17.0  1.0      2.0    1.0\n",
      "2                           1.0                 0.0  15.0  2.0      6.0    1.0\n",
      "3                           1.0                 0.0  15.0  1.0      0.0    1.0\n",
      "4                           1.0                 0.0  16.0  1.0      0.0    1.0\n",
      "...                         ...                 ...   ...  ...      ...    ...\n",
      "644                         1.0                 0.0  19.0  1.0      4.0    1.0\n",
      "645                         1.0                 0.0  18.0  1.0      4.0    1.0\n",
      "646                         1.0                 0.0  18.0  1.0      6.0    1.0\n",
      "647                         1.0                 1.0  17.0  3.0      6.0    0.0\n",
      "648                         1.0                 1.0  18.0  3.0      4.0    0.0\n",
      "\n",
      "[649 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Sex|Walc Fairness Metric Calculation\n",
    "dataset_sex_walc = StandardDataset(df, \n",
    "                               label_name='Walc', \n",
    "                               favorable_classes=[1,2,3],\n",
    "                               protected_attribute_names=['sex'], \n",
    "                               privileged_classes=[[0]],\n",
    "                               features_to_keep=['age','Dalc','absences']\n",
    "                              )\n",
    "print(dataset_sex_walc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f48fb284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Imapct of unprivileged and privileged groups = 0.711602\n",
      "SPD of unprivileged and privileged groups = -0.260537\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_sex_walc, \n",
    "                                             unprivileged_groups=unprivileged_groups_sex,\n",
    "                                             privileged_groups=privileged_groups_sex)\n",
    "display(Markdown(\"#### Original dataset\"))\n",
    "print(\"Disparate Imapct of unprivileged and privileged groups = %f\" % metric_orig_train.disparate_impact())\n",
    "print(\"SPD of unprivileged and privileged groups = %f\" % metric_orig_train.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc1e8dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               instance weights features                                    \\\n",
      "                                         protected attribute                 \n",
      "                                     sex                 age Walc absences   \n",
      "instance names                                                               \n",
      "0                           1.0      0.0                 0.0  1.0      4.0   \n",
      "1                           1.0      0.0                 1.0  1.0      2.0   \n",
      "2                           1.0      0.0                 1.0  3.0      6.0   \n",
      "3                           1.0      0.0                 1.0  1.0      0.0   \n",
      "4                           1.0      0.0                 1.0  2.0      0.0   \n",
      "...                         ...      ...                 ...  ...      ...   \n",
      "644                         1.0      0.0                 0.0  2.0      4.0   \n",
      "645                         1.0      0.0                 0.0  1.0      4.0   \n",
      "646                         1.0      0.0                 0.0  1.0      6.0   \n",
      "647                         1.0      1.0                 1.0  4.0      6.0   \n",
      "648                         1.0      1.0                 0.0  4.0      4.0   \n",
      "\n",
      "               labels  \n",
      "                       \n",
      "                       \n",
      "instance names         \n",
      "0                 1.0  \n",
      "1                 1.0  \n",
      "2                 1.0  \n",
      "3                 1.0  \n",
      "4                 1.0  \n",
      "...               ...  \n",
      "644               1.0  \n",
      "645               1.0  \n",
      "646               1.0  \n",
      "647               1.0  \n",
      "648               1.0  \n",
      "\n",
      "[649 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Age|Dalc Fairness Metric Calculation\n",
    "dataset_age_dalc = StandardDataset(df, \n",
    "                               label_name='Dalc', \n",
    "                               favorable_classes=[1,2,3],\n",
    "                               protected_attribute_names=['age'], \n",
    "                               privileged_classes=[lambda x: x < 18],\n",
    "                               features_to_keep=['sex','Walc','absences']\n",
    "                              )\n",
    "privileged_groups_age = [{'age': 1}]\n",
    "unprivileged_groups_age = [{'age': 0}]\n",
    "print(dataset_age_dalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cfedda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Imapct of unprivileged and privileged groups = 0.940231\n",
      "SPD of unprivileged and privileged groups = -0.057598\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_age_dalc, \n",
    "                                             unprivileged_groups=unprivileged_groups_age,\n",
    "                                             privileged_groups=privileged_groups_age)\n",
    "display(Markdown(\"#### Original dataset\"))\n",
    "print(\"Disparate Imapct of unprivileged and privileged groups = %f\" % metric_orig_train.disparate_impact())\n",
    "print(\"SPD of unprivileged and privileged groups = %f\" % metric_orig_train.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57d80c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               instance weights features                                    \\\n",
      "                                         protected attribute                 \n",
      "                                     sex                 age Dalc absences   \n",
      "instance names                                                               \n",
      "0                           1.0      0.0                 0.0  1.0      4.0   \n",
      "1                           1.0      0.0                 1.0  1.0      2.0   \n",
      "2                           1.0      0.0                 1.0  2.0      6.0   \n",
      "3                           1.0      0.0                 1.0  1.0      0.0   \n",
      "4                           1.0      0.0                 1.0  1.0      0.0   \n",
      "...                         ...      ...                 ...  ...      ...   \n",
      "644                         1.0      0.0                 0.0  1.0      4.0   \n",
      "645                         1.0      0.0                 0.0  1.0      4.0   \n",
      "646                         1.0      0.0                 0.0  1.0      6.0   \n",
      "647                         1.0      1.0                 1.0  3.0      6.0   \n",
      "648                         1.0      1.0                 0.0  3.0      4.0   \n",
      "\n",
      "               labels  \n",
      "                       \n",
      "                       \n",
      "instance names         \n",
      "0                 1.0  \n",
      "1                 1.0  \n",
      "2                 1.0  \n",
      "3                 1.0  \n",
      "4                 1.0  \n",
      "...               ...  \n",
      "644               1.0  \n",
      "645               1.0  \n",
      "646               1.0  \n",
      "647               0.0  \n",
      "648               0.0  \n",
      "\n",
      "[649 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3 - Age|Walc Fairness Metric Calculation\n",
    "dataset_age_walc = StandardDataset(df, \n",
    "                               label_name='Walc', \n",
    "                               favorable_classes=[1,2,3],\n",
    "                               protected_attribute_names=['age'], \n",
    "                               privileged_classes=[lambda x: x < 18],\n",
    "                               features_to_keep=['sex','Dalc','absences']\n",
    "                              )\n",
    "print(dataset_age_walc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfd51214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Imapct of unprivileged and privileged groups = 0.950802\n",
      "SPD of unprivileged and privileged groups = -0.039737\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_age_walc, \n",
    "                                             unprivileged_groups=unprivileged_groups_age,\n",
    "                                             privileged_groups=privileged_groups_age)\n",
    "display(Markdown(\"#### Original dataset\"))\n",
    "print(\"Disparate Imapct of unprivileged and privileged groups = %f\" % metric_orig_train.disparate_impact())\n",
    "print(\"SPD of unprivileged and privileged groups = %f\" % metric_orig_train.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba2db9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Preprocessing Algorithm - Sex|Dalc Fairness Metric Calculation\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups_sex,\n",
    "                privileged_groups=privileged_groups_sex)\n",
    "dataset_transf_sex_dalc = RW.fit_transform(dataset_sex_dalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eba4fd2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Imapct of unprivileged and privileged groups = 1.000000\n",
      "SPD of unprivileged and privileged groups = 0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_transf_sex_dalc, \n",
    "                                             unprivileged_groups=unprivileged_groups_sex,\n",
    "                                             privileged_groups=privileged_groups_sex)\n",
    "display(Markdown(\"#### Transformed dataset\"))\n",
    "print(\"Disparate Imapct of unprivileged and privileged groups = %f\" % metric_orig_train.disparate_impact())\n",
    "print(\"SPD of unprivileged and privileged groups = %f\" % metric_orig_train.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3f447b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Preprocessing Algorithm - Age|Dalc Fairness Metric Calculation\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups_age,\n",
    "                privileged_groups=privileged_groups_age)\n",
    "dataset_transf_age_dalc = RW.fit_transform(dataset_age_dalc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78e744f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Transformed dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate Imapct of unprivileged and privileged groups = 1.000000\n",
      "SPD of unprivileged and privileged groups = 0.000000\n"
     ]
    }
   ],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(dataset_transf_age_dalc, \n",
    "                                             unprivileged_groups=unprivileged_groups_age,\n",
    "                                             privileged_groups=privileged_groups_age)\n",
    "display(Markdown(\"#### Transformed dataset\"))\n",
    "print(\"Disparate Imapct of unprivileged and privileged groups = %f\" % metric_orig_train.disparate_impact())\n",
    "print(\"SPD of unprivileged and privileged groups = %f\" % metric_orig_train.statistical_parity_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9d18733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename variable for Step 4 (Sex)\n",
    "dataset_orig = StandardDataset(df, \n",
    "                               label_name='Dalc', \n",
    "                               favorable_classes=[1,2,3],\n",
    "                               protected_attribute_names=['sex'], \n",
    "                               privileged_classes=[[0]],\n",
    "                               features_to_keep=['age','Walc','absences']\n",
    "                              )\n",
    "privileged_groups = [{'sex': 0}]\n",
    "unprivileged_groups = [{'sex': 1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5a29b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename variable for Step 4 (Sex)\n",
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "                privileged_groups=privileged_groups)\n",
    "dataset_transf = RW.fit_transform(dataset_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c6cb2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.7], shuffle=True)\n",
    "dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c756435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classifier and predictions\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
    "y_train = dataset_orig_train.labels.ravel()\n",
    "w_train = dataset_orig_train.instance_weights.ravel()\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train, \n",
    "         sample_weight=dataset_orig_train.instance_weights)\n",
    "y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "# positive class index\n",
    "pos_ind = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
    "\n",
    "dataset_orig_train_pred = dataset_orig_train.copy()\n",
    "dataset_orig_train_pred.labels = y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "03353430",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
    "X_valid = scale_orig.transform(dataset_orig_valid_pred.features)\n",
    "y_valid = dataset_orig_valid_pred.labels\n",
    "dataset_orig_valid_pred.scores = lmod.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
    "X_test = scale_orig.transform(dataset_orig_test_pred.features)\n",
    "y_test = dataset_orig_test_pred.labels\n",
    "dataset_orig_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f64b24eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_thresh = 100\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    fav_inds = dataset_orig_valid_pred.scores > class_thresh\n",
    "    dataset_orig_valid_pred.labels[fav_inds] = dataset_orig_valid_pred.favorable_label\n",
    "    dataset_orig_valid_pred.labels[~fav_inds] = dataset_orig_valid_pred.unfavorable_label\n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_orig_valid,\n",
    "                                             dataset_orig_valid_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    \n",
    "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
    "                       +classified_metric_orig_valid.true_negative_rate())\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44c6a931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Predictions from original testing data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification threshold used = 0.7821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]invalid value encountered in double_scalars\n",
      "invalid value encountered in double_scalars\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1190.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.8175\n",
      "Statistical parity difference = -0.1042\n",
      "Disparate impact = 0.8958\n",
      "Average odds difference = nan\n",
      "Equal opportunity difference = -0.0667\n",
      "Theil index = 0.0351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Predictions from original testing data\"))\n",
    "bal_acc_arr_orig = []\n",
    "disp_imp_arr_orig = []\n",
    "avg_odds_diff_arr_orig = []\n",
    "\n",
    "print(\"Classification threshold used = %.4f\" % best_class_thresh)\n",
    "for thresh in tqdm(class_thresh_arr):\n",
    "    \n",
    "    if thresh == best_class_thresh:\n",
    "        disp = True\n",
    "    else:\n",
    "        disp = False\n",
    "    \n",
    "    fav_inds = dataset_orig_test_pred.scores > thresh\n",
    "    dataset_orig_test_pred.labels[fav_inds] = dataset_orig_test_pred.favorable_label\n",
    "    dataset_orig_test_pred.labels[~fav_inds] = dataset_orig_test_pred.unfavorable_label\n",
    "    \n",
    "    metric_test_bef = compute_metrics(dataset_orig_test, dataset_orig_test_pred, \n",
    "                                      unprivileged_groups, privileged_groups,\n",
    "                                      disp = disp)\n",
    "\n",
    "    bal_acc_arr_orig.append(metric_test_bef[\"Balanced accuracy\"])\n",
    "    avg_odds_diff_arr_orig.append(metric_test_bef[\"Average odds difference\"])\n",
    "    disp_imp_arr_orig.append(metric_test_bef[\"Disparate impact\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc7d2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_train, dataset_transf_vt = dataset_transf.split([0.7], shuffle=True)\n",
    "dataset_transf_valid, dataset_transf_test = dataset_transf_vt.split([0.5], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fb58473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classifier and predictions\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dataset_transf_train.features)\n",
    "y_train = dataset_transf_train.labels.ravel()\n",
    "w_train = dataset_transf_train.instance_weights.ravel()\n",
    "\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train, \n",
    "         sample_weight=dataset_transf_train.instance_weights)\n",
    "y_train_pred = lmod.predict(X_train)\n",
    "\n",
    "# positive class index\n",
    "pos_ind = np.where(lmod.classes_ == dataset_transf_train.favorable_label)[0][0]\n",
    "\n",
    "dataset_transf_train_pred = dataset_transf_train.copy()\n",
    "dataset_transf_train_pred.labels = y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "15de9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_transf_valid_pred = dataset_transf_valid.copy(deepcopy=True)\n",
    "X_valid = scale_orig.transform(dataset_transf_valid_pred.features)\n",
    "y_valid = dataset_transf_valid_pred.labels\n",
    "dataset_transf_valid_pred.scores = lmod.predict_proba(X_valid)[:,pos_ind].reshape(-1,1)\n",
    "\n",
    "dataset_transf_test_pred = dataset_transf_test.copy(deepcopy=True)\n",
    "X_test = scale_orig.transform(dataset_transf_test_pred.features)\n",
    "y_test = dataset_transf_test_pred.labels\n",
    "dataset_transf_test_pred.scores = lmod.predict_proba(X_test)[:,pos_ind].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c6b531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_thresh = 100\n",
    "ba_arr = np.zeros(num_thresh)\n",
    "class_thresh_arr = np.linspace(0.01, 0.99, num_thresh)\n",
    "for idx, class_thresh in enumerate(class_thresh_arr):\n",
    "    fav_inds = dataset_transf_valid_pred.scores > class_thresh\n",
    "    dataset_transf_valid_pred.labels[fav_inds] = dataset_transf_valid_pred.favorable_label\n",
    "    dataset_transf_valid_pred.labels[~fav_inds] = dataset_transf_valid_pred.unfavorable_label\n",
    "    classified_metric_orig_valid = ClassificationMetric(dataset_transf_valid,\n",
    "                                             dataset_transf_valid_pred, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "    \n",
    "    ba_arr[idx] = 0.5*(classified_metric_orig_valid.true_positive_rate()\\\n",
    "                       +classified_metric_orig_valid.true_negative_rate())\n",
    "best_ind = np.where(ba_arr == np.max(ba_arr))[0][0]\n",
    "best_class_thresh = class_thresh_arr[best_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "caf7aa46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Predictions from transformed testing data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification threshold used = 0.8019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy = 0.8310"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1176.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical parity difference = 0.0721\n",
      "Disparate impact = 1.0811\n",
      "Average odds difference = 0.3569\n",
      "Equal opportunity difference = 0.0471\n",
      "Theil index = 0.0603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Predictions from transformed testing data\"))\n",
    "bal_acc_arr_orig = []\n",
    "disp_imp_arr_orig = []\n",
    "avg_odds_diff_arr_orig = []\n",
    "\n",
    "print(\"Classification threshold used = %.4f\" % best_class_thresh)\n",
    "for thresh in tqdm(class_thresh_arr):\n",
    "    \n",
    "    if thresh == best_class_thresh:\n",
    "        disp = True\n",
    "    else:\n",
    "        disp = False\n",
    "    \n",
    "    fav_inds = dataset_transf_test_pred.scores > thresh\n",
    "    dataset_transf_test_pred.labels[fav_inds] = dataset_transf_test_pred.favorable_label\n",
    "    dataset_transf_test_pred.labels[~fav_inds] = dataset_transf_test_pred.unfavorable_label\n",
    "    \n",
    "    metric_test_bef = compute_metrics(dataset_transf_test, dataset_transf_test_pred, \n",
    "                                      unprivileged_groups, privileged_groups,\n",
    "                                      disp = disp)\n",
    "\n",
    "    bal_acc_arr_orig.append(metric_test_bef[\"Balanced accuracy\"])\n",
    "    avg_odds_diff_arr_orig.append(metric_test_bef[\"Average odds difference\"])\n",
    "    disp_imp_arr_orig.append(metric_test_bef[\"Disparate impact\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf177b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "a84b83ea2f86295e20a02d031ecd8cb390a3bc9bb86bd0bad847c42e05008772"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
